tensorflowはくせが強いです

基本的に、グラフという概念を導入しているらしい
NNを作るときにみやすくなったりするらしい！

グラフとは、ノードをつないでいく
ノードはinputだったりoutputだったりするの
　inputが何もない場合は、定数として扱う

そうゆうもんらしいということで!!

Tensor()
↑はテンソルを定義することができたらしい。
・これをデータとして取得したい場合は、グラフを実行すると返り値として戻ってくる
・グラフを実行するさいには、sessionを定義してグラフを埋め込むことで実行することができる

●定数の代入
●足し算の実装
	node3を実行すると、同時にnode1とnode2も実行される
●変数の定義
	配列を設定することもできる	
実行するときには、引数を与えてあげる。
最終的にNNの初期設定の初期値をですね、パラメーターを引数で与えてあげて、
最後の出力層のノードを実行するとすべての、ニューラルネットの入力層だったりとかの定義が
すべてが実行されて、モデルの出力が得られる！

●初期値のある変数の設定
	Variableで設定
	初期化する必要がある
		tf.global_variables_initializer()


●線形回帰について
	最小二乗法を使用する
	loss は差分の合計を集計する

	optimizerで最適化する
	tf.train.Gra--ってのが学習率を求めるやつかな
		そしてoptimizer.minimize(loss)ってのが重みとバイアスの最適化かな

●●多層パーセプトロン
sklearn.datasets からmnistを取得する
	できない可能性ある（おれができなかったから、それはファイルをアップロードする）


onehotで表現する！なぜかを説明する

バッチ学習するから画像の数はNoneにする！　入る配列は決まってるから固定にする


	第一層でdropout率をどうするかっての！
	重みの層をランダム初期化する（とても大事なので割愛！）
	バイアルは０でする

###それぞれの式の説明の必要だぞ
コスト関数はコストエントロピーを使う
最適化関数はAdamを使う
accuracy（精度）をだす関数を作る

from sklearn.model_selectoin import trian_test_splitについて
何かを前処理したらしい感じそこが大事だがな、、
mapとかlambdaとか、、、うえーー

	batch_sizeについて一回で何枚の画像を入力するか
	入力画像が49000だった場合は、/100をすることで
		1epochが490回の更新になる。そしてepochが20だと*20回分繰り返す

random_sampleについて
	randomで画像を取得するようにする
	randomでXとyを取得する

batch学習について

i == 0っていうのはepoch開始時のデータ

更新が悪くなった場合は別のやつにデータを入れれるような感じにしている
それから処理開始



●●セクション7:Deep Learning
deep learningとは
４層以上の多層ニューラルネットワークによる機械学習手法

画像認識：Convolutional Neural Network

言語処理、音声認識
	Recurrent Neural Network
	Long short-term memory

DLでは特徴量設計が必要ない (End to End)
	画像の入力から出力まで学習できる
		よく聞くメリットだな！


CNNについて
	NNについて”抽象化”の概念を導入
	どう表現するか？
		畳み込み(convolution)を使用している

