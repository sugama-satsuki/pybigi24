{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chainerによるCNNの実装\n",
    "\n",
    "参考1:http://docs.chainer.org/en/stable/tutorial/convnet.html\n",
    "\n",
    "\n",
    "参考2:http://yann.lecun.com/exdb/lenet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの定義\n",
    "参考1 :http://docs.chainer.org/en/stable/reference/links.html\n",
    "\n",
    "\n",
    "参考2 :http://docs.chainer.org/en/stable/reference/functions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "\n",
    "class LeNet5(chainer.Chain):\n",
    "    \n",
    "    def __init__(self, hidden_layer = 84, n_out = 10):\n",
    "        super(LeNet5, self).__init__(\n",
    "            #畳み込み層と全結合ニューラルネットワークを実装する\n",
    "            conv1 = L.Convolution2D(in_channels=None, out_channels=6, ksize=5, stride=1),\n",
    "            conv2 = L.Convolution2D(in_channels=None, out_channels=16, ksize=5, stride=1),\n",
    "            conv3 = L.Convolution2D(in_channels=None, out_channels=120, ksize=4, stride=1),\n",
    "            fc4 = L.Linear(None, hidden_layer),\n",
    "            fc5 = L.Linear(hidden_layer, n_out),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.sigmoid(self.conv1(x))\n",
    "        h = F.max_pooling_2d(h, 2,2)\n",
    "        h = F.sigmoid(self.conv2(h))\n",
    "        h = F.max_pooling_2d(h, 2,2)\n",
    "        h = F.sigmoid(self.conv3(h))\n",
    "        h = F.sigmoid(self.fc4(h))\n",
    "        return F.softmax(self.fc5(h))\n",
    "\n",
    "model = LeNet5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 784)\n",
      "(49000, 1, 28, 28)\n",
      "===============================================\n",
      "epoch : 1\n",
      "train loss : 2.0757102966308594\n",
      "train acc : 0.41632652282714844\n",
      "test loss : 2.0983870029449463\n",
      "test acc : 0.38499999046325684\n",
      "===============================================\n",
      "epoch : 2\n",
      "train loss : 1.84274423122406\n",
      "train acc : 0.704081654548645\n",
      "test loss : 1.8448294401168823\n",
      "test acc : 0.6975714564323425\n",
      "===============================================\n",
      "epoch : 3\n",
      "train loss : 1.6400668621063232\n",
      "train acc : 0.8571428656578064\n",
      "test loss : 1.662094235420227\n",
      "test acc : 0.8326190710067749\n",
      "===============================================\n",
      "epoch : 4\n",
      "train loss : 1.6305872201919556\n",
      "train acc : 0.8469387888908386\n",
      "test loss : 1.622395396232605\n",
      "test acc : 0.8537142872810364\n",
      "===============================================\n",
      "epoch : 5\n",
      "train loss : 1.6026374101638794\n",
      "train acc : 0.8734694123268127\n",
      "test loss : 1.6072611808776855\n",
      "test acc : 0.8629047870635986\n",
      "===============================================\n",
      "epoch : 6\n",
      "train loss : 1.6033226251602173\n",
      "train acc : 0.863265335559845\n",
      "test loss : 1.5977202653884888\n",
      "test acc : 0.8700952529907227\n",
      "===============================================\n",
      "epoch : 7\n",
      "train loss : 1.5487549304962158\n",
      "train acc : 0.9306122660636902\n",
      "test loss : 1.537280559539795\n",
      "test acc : 0.9450476169586182\n",
      "===============================================\n",
      "epoch : 8\n",
      "train loss : 1.5140645503997803\n",
      "train acc : 0.9571428298950195\n",
      "test loss : 1.5163542032241821\n",
      "test acc : 0.9562857151031494\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-d909894b182f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m#学習\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleargrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kento/anaconda/envs/py35Conda/lib/python3.5/site-packages/chainer/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, retain_grad)\u001b[0m\n\u001b[1;32m    716\u001b[0m             func.output_data = tuple(\n\u001b[1;32m    717\u001b[0m                 [None if y is None else y.data for y in outputs])\n\u001b[0;32m--> 718\u001b[0;31m             \u001b[0mgxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgxs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_retain_after_backward'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kento/anaconda/envs/py35Conda/lib/python3.5/site-packages/chainer/function.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, inputs, grad_outputs)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kento/anaconda/envs/py35Conda/lib/python3.5/site-packages/chainer/functions/activation/sigmoid.py\u001b[0m in \u001b[0;36mbackward_cpu\u001b[0;34m(self, x, gy)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mone\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from chainer import iterators\n",
    "#訓練データとテストデータの準備\n",
    "from sklearn.model_selection import train_test_split\n",
    "#X = np.array([e.astype(np.float32) for e in mnist.data])\n",
    "#y = np.array([e.astype(np.int32) for e in mnist.target])\n",
    "\n",
    "X = np.array(mnist.data).astype(np.float32)\n",
    "y = np.array(mnist.target).astype(np.int32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# 画像を (nsample, channel, height, width) の4次元テンソルに変換\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(X_train.shape)\n",
    "X_train = X_train.reshape((-1, 1, 28,28))\n",
    "X_test = X_test.reshape((-1, 1, 28, 28))\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "#バッチ学習のためのバッチサイズを指定\n",
    "#とりあえず、訓練データ49000の1/100で指定\n",
    "batch_size = 490\n",
    "\n",
    "dataset_train = []\n",
    "\n",
    "for X, y in zip(X_train, y_train):\n",
    "    dataset_train.append((X, y))\n",
    "\n",
    "train_iterator = iterators.SerialIterator(dataset_train, batch_size)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "max_epoch = 10\n",
    "train_acc_log = []\n",
    "test_acc_log = []\n",
    "train_loss_log = []\n",
    "test_loss_log = []\n",
    "\n",
    "train_iterator = iterators.SerialIterator(dataset_train, batch_size)\n",
    "\n",
    "while train_iterator.epoch < max_epoch:\n",
    "    #バッチのデータを用意\n",
    "    batch = train_iterator.next()\n",
    "    X_batch, y_batch = chainer.dataset.concat_examples(batch)\n",
    "\n",
    "    #コストを計算\n",
    "    y_train_predicted = model(X_batch)\n",
    "    loss_train = F.softmax_cross_entropy(y_train_predicted, y_batch)\n",
    "    \n",
    "    #学習\n",
    "    model.cleargrads()\n",
    "    loss_train.backward()\n",
    "    optimizer.update()\n",
    "    \n",
    "    #精度の確認\n",
    "    acc_train = F.accuracy(y_train_predicted, y_batch)\n",
    "    train_acc_log.append(float(acc_train.data))\n",
    "    train_loss_log.append(float(loss_train.data))\n",
    "    \n",
    "    #test\n",
    "    if train_iterator.is_new_epoch:\n",
    "        print(\"===============================================\")\n",
    "        y_test_predicted = model(X_test)\n",
    "        loss_test = F.softmax_cross_entropy(y_test_predicted, y_test)\n",
    "        acc_test = F.accuracy(y_test_predicted, y_test)\n",
    "\n",
    "        test_acc_log.append(float(acc_test.data))\n",
    "        test_loss_log.append(float(loss_test.data))\n",
    "\n",
    "        print(\"epoch : {}\".format(train_iterator.epoch))\n",
    "        print(\"train loss : {}\".format(float(loss_train.data)))\n",
    "        print(\"train acc : {}\".format(float(acc_train.data)))\n",
    "        print(\"test loss : {}\".format(float(loss_test.data)))\n",
    "        print(\"test acc : {}\".format(float(acc_test.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflowによるCNNの実装\n",
    "参考1 :https://www.tensorflow.org/tutorials/deep_cnn\n",
    "\n",
    "参考2 :https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/examples/tutorials/mnist/mnist_deep.py#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[1 0 0 0 0 0 0 0 0 0] 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "\n",
    "X = mnist.data\n",
    "y = mnist.target\n",
    "\n",
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(range(0,10))\n",
    "print(lb.classes_)\n",
    "y_onehot = lb.transform(y)\n",
    "print(y_onehot[0], y[0])\n",
    "\n",
    "X_train, X_test, y_train, y_test = map(lambda x : np.array(x).astype(np.float32), train_test_split(X, y_onehot, test_size=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    #標準偏差0.01で切断正規分布(truncated normal distribution)にしたがって初期値をランダム生成\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.0, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    #ストライドは、[1, stride, stride, 1]\n",
    "    #畳み込みの際、端がたたみ込まれる回数が少なくなるのを防ぐための0 padding。\"SAME\"でonに\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    #2*2の4マスの最大値を一つとして、圧縮する\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "#入力を画像セットとして、出力がnnの出力(10クラス)\n",
    "def lenet5(x):\n",
    "    x_input = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    \n",
    "    #畳み込み層1\n",
    "    #[filter_height, filter_width, in_channels, channel_multiplier]\n",
    "    W_conv1 = weight_variable([5, 5, 1, 6])\n",
    "    b_conv1 = bias_variable([6])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_input, W_conv1) + b_conv1)\n",
    "    #14*14に\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "    \n",
    "    #畳み込み層2\n",
    "    #[filter_size, input, output]\n",
    "    W_conv2 = weight_variable([5, 5, 6, 16])\n",
    "    b_conv2 = bias_variable([16])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    #7*7に\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "    \n",
    "    \n",
    "    #全結合層１\n",
    "    W_fc1 = weight_variable([7*7*16, 120])\n",
    "    b_fc1 = bias_variable([120])\n",
    "    \n",
    "    #linearに渡すときは、flatにする\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*16])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "    #全結合層2\n",
    "    W_fc2 = weight_variable([120, 64])\n",
    "    b_fc2 = bias_variable([64])\n",
    "    h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "    \n",
    "    \n",
    "    #全結合層3\n",
    "    W_fc3 = weight_variable([64, 10])\n",
    "    b_fc3 = bias_variable([10])\n",
    "    h_fc3 = tf.nn.relu(tf.matmul(h_fc2, W_fc3) + b_fc3)\n",
    "    \n",
    "    return h_fc3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = tf.placeholder(tf.float32, [None, 784])\n",
    "y_teacher = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "y_out = lenet5(x_input)\n",
    "\n",
    "#コスト関数\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_teacher,logits=y_out)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "#最適化関数\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cross_entropy)\n",
    "\n",
    "#ソフトマックスの確率最大の場所が、\n",
    "correct_prediction = tf.equal(tf.argmax(y_out, 1), tf.argmax(y_teacher, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================\n",
      "1 : training accuracy 10.000000149011612%\n",
      "1 : test accuracy 8.4428571164608%\n",
      "Validation accuracy improved: 8.4428571164608%. Saving the network.\n",
      "=======================================\n",
      "2 : training accuracy 73.00000190734863%\n",
      "2 : test accuracy 70.8476185798645%\n",
      "Validation accuracy improved: 70.8476185798645%. Saving the network.\n",
      "=======================================\n",
      "3 : training accuracy 75.99999904632568%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-3c772dd2bc4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} : training accuracy {}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             test_accuracy = sess.run(accuracy, feed_dict={\n\u001b[0;32m---> 35\u001b[0;31m                 x_input: X_test, y_teacher: y_test, keep_prob_input: 1.0, keep_prob: 1.0})\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} : test accuracy {}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kento/anaconda/envs/py35Conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kento/anaconda/envs/py35Conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kento/anaconda/envs/py35Conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kento/anaconda/envs/py35Conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kento/anaconda/envs/py35Conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train:49000なので、100バッチ490回\n",
    "import random\n",
    "# create a saver\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# initialize the graph\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "saver.save(sess, 'mnist_fc_best')\n",
    "\n",
    "batch_size = 100\n",
    "epoch_size = 20\n",
    "best_accuracy = 0.0\n",
    "\n",
    "def random_sample(X, y, size = 100):\n",
    "    idx = range(0 , len(y))\n",
    "    random_idx = random.sample(idx, size)\n",
    "    return X[random_idx, :], y[random_idx, :]\n",
    "\n",
    "for epoch in range(1, epoch_size+1):\n",
    "    #バッチ学習\n",
    "    for i in range(int(len(y_train)/batch_size)):\n",
    "        X_batch, y_batch = random_sample(X_train, y_train, 100)\n",
    "        #学習\n",
    "        #バッチの初めにプリント\n",
    "        if i == 0:\n",
    "            print(\"=======================================\")\n",
    "            #精度確認のときは、drop outしない\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={\n",
    "                x_input: X_batch, y_teacher : y_batch, keep_prob_input: 1.0, keep_prob: 1.0})\n",
    "            print(\"{} : training accuracy {}%\".format(epoch, train_accuracy*100))\n",
    "            test_accuracy = sess.run(accuracy, feed_dict={\n",
    "                x_input: X_test, y_teacher: y_test, keep_prob_input: 1.0, keep_prob: 1.0})\n",
    "            print(\"{} : test accuracy {}%\".format(epoch, test_accuracy*100))\n",
    "\n",
    "            #ループの中で、最高の精度を持つネットワークを保存したい\n",
    "            if test_accuracy >= best_accuracy:\n",
    "                saver.save(sess, 'mnist_fc_best')\n",
    "                best_accuracy = test_accuracy\n",
    "                print(\"Validation accuracy improved: {}%. Saving the network.\".format(test_accuracy*100))\n",
    "            else:\n",
    "                #テストaccuracyが下がったときは、過学習なので1epoch前のモデルに戻す\n",
    "                saver.restore(sess, 'mnist_fc_best')\n",
    "                print(\"restore!!!! now : {}, before : {}\".format(test_accuracy*100, best_accuracy*100))\n",
    "    \n",
    "        #バッチ学習\n",
    "        #過学習を防ぐためにdrop out率を設定\n",
    "        sess.run(optimizer, feed_dict={\n",
    "                x_input: X_batch, y_teacher: y_batch, keep_prob_input: 0.9, keep_prob: 1.0})\n",
    "\n",
    "print(\"Best test accuracy: %g\" % best_accuracy*100)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
